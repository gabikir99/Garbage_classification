{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6203f449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0c473ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLO model\n",
    "yolo_model = YOLO(\"best_yolo.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c10c196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 192, kernel_size=(16, 16), stride=(16, 16))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (norm_pre): Identity()\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "  (fc_norm): Identity()\n",
       "  (head): Linear(in_features=192, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit_model = timm.create_model('vit_tiny_patch16_224', pretrained=False, num_classes=6)\n",
    "state_dict = torch.load(\"best_vit_model.pth\", map_location='cpu')\n",
    "vit_model.load_state_dict(state_dict)\n",
    "vit_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12a8abbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e1a0cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['BIODEGRADABLE', 'CARDBOARD', 'GLASS', 'METAL', 'PAPER', 'PLASTIC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e36cfbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 320x416 1 PAPER, 73.2ms\n",
      "Speed: 1.8ms preprocess, 73.2ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 78.1ms\n",
      "Speed: 1.0ms preprocess, 78.1ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 79.4ms\n",
      "Speed: 1.5ms preprocess, 79.4ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 73.9ms\n",
      "Speed: 0.9ms preprocess, 73.9ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 65.6ms\n",
      "Speed: 1.0ms preprocess, 65.6ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 62.1ms\n",
      "Speed: 1.2ms preprocess, 62.1ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 68.0ms\n",
      "Speed: 0.9ms preprocess, 68.0ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 68.5ms\n",
      "Speed: 1.3ms preprocess, 68.5ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 67.3ms\n",
      "Speed: 2.0ms preprocess, 67.3ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 1 PAPER, 65.3ms\n",
      "Speed: 1.0ms preprocess, 65.3ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 1 PAPER, 65.6ms\n",
      "Speed: 0.9ms preprocess, 65.6ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 65.5ms\n",
      "Speed: 1.2ms preprocess, 65.5ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 1 PAPER, 64.1ms\n",
      "Speed: 1.1ms preprocess, 64.1ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 1 PAPER, 64.2ms\n",
      "Speed: 1.1ms preprocess, 64.2ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 1 PAPER, 62.2ms\n",
      "Speed: 1.7ms preprocess, 62.2ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 72.8ms\n",
      "Speed: 1.3ms preprocess, 72.8ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 67.4ms\n",
      "Speed: 1.1ms preprocess, 67.4ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 71.9ms\n",
      "Speed: 1.0ms preprocess, 71.9ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 1 PAPER, 65.0ms\n",
      "Speed: 1.0ms preprocess, 65.0ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 1 PAPER, 65.8ms\n",
      "Speed: 1.4ms preprocess, 65.8ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 1 PAPER, 64.5ms\n",
      "Speed: 1.0ms preprocess, 64.5ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 1 PAPER, 63.0ms\n",
      "Speed: 1.3ms preprocess, 63.0ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 61.5ms\n",
      "Speed: 1.3ms preprocess, 61.5ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 1 PAPER, 62.7ms\n",
      "Speed: 1.0ms preprocess, 62.7ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 1 PAPER, 61.1ms\n",
      "Speed: 1.1ms preprocess, 61.1ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 1 PAPER, 60.3ms\n",
      "Speed: 1.0ms preprocess, 60.3ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 61.5ms\n",
      "Speed: 1.1ms preprocess, 61.5ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 63.2ms\n",
      "Speed: 1.2ms preprocess, 63.2ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 62.6ms\n",
      "Speed: 1.0ms preprocess, 62.6ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 1 PAPER, 60.9ms\n",
      "Speed: 1.2ms preprocess, 60.9ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 METAL, 1 PAPER, 60.7ms\n",
      "Speed: 0.9ms preprocess, 60.7ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 1 PAPER, 62.2ms\n",
      "Speed: 1.0ms preprocess, 62.2ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 1 PAPER, 65.2ms\n",
      "Speed: 1.4ms preprocess, 65.2ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 1 PAPER, 65.2ms\n",
      "Speed: 1.1ms preprocess, 65.2ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 62.4ms\n",
      "Speed: 0.9ms preprocess, 62.4ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 1 PAPER, 61.4ms\n",
      "Speed: 1.8ms preprocess, 61.4ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 1 PAPER, 65.5ms\n",
      "Speed: 0.9ms preprocess, 65.5ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 1 PAPER, 61.9ms\n",
      "Speed: 1.0ms preprocess, 61.9ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 1 PAPER, 59.9ms\n",
      "Speed: 1.0ms preprocess, 59.9ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 1 PAPER, 62.1ms\n",
      "Speed: 1.0ms preprocess, 62.1ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 1 PAPER, 63.3ms\n",
      "Speed: 1.0ms preprocess, 63.3ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 METAL, 1 PAPER, 62.7ms\n",
      "Speed: 1.4ms preprocess, 62.7ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 METAL, 1 PAPER, 62.3ms\n",
      "Speed: 0.9ms preprocess, 62.3ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 METAL, 69.4ms\n",
      "Speed: 0.9ms preprocess, 69.4ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 76.2ms\n",
      "Speed: 1.0ms preprocess, 76.2ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 METAL, 1 PAPER, 77.7ms\n",
      "Speed: 1.0ms preprocess, 77.7ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 71.8ms\n",
      "Speed: 1.4ms preprocess, 71.8ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 METAL, 1 PAPER, 66.5ms\n",
      "Speed: 0.9ms preprocess, 66.5ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 METAL, 1 PAPER, 1 PLASTIC, 64.2ms\n",
      "Speed: 1.1ms preprocess, 64.2ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 1 PAPER, 1 PLASTIC, 62.1ms\n",
      "Speed: 1.1ms preprocess, 62.1ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 60.8ms\n",
      "Speed: 1.1ms preprocess, 60.8ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 63.6ms\n",
      "Speed: 1.1ms preprocess, 63.6ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 1 PAPER, 63.5ms\n",
      "Speed: 1.2ms preprocess, 63.5ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 1 PAPER, 61.2ms\n",
      "Speed: 0.8ms preprocess, 61.2ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 METAL, 1 PAPER, 61.3ms\n",
      "Speed: 1.1ms preprocess, 61.3ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 METAL, 1 PAPER, 60.1ms\n",
      "Speed: 1.0ms preprocess, 60.1ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 63.8ms\n",
      "Speed: 1.1ms preprocess, 63.8ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 63.0ms\n",
      "Speed: 1.2ms preprocess, 63.0ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 PAPER, 62.5ms\n",
      "Speed: 1.3ms preprocess, 62.5ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 METAL, 63.7ms\n",
      "Speed: 1.0ms preprocess, 63.7ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 PAPER, 63.7ms\n",
      "Speed: 0.9ms preprocess, 63.7ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 1 CARDBOARD, 1 METAL, 1 PAPER, 61.4ms\n",
      "Speed: 1.4ms preprocess, 61.4ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 1 PAPER, 62.0ms\n",
      "Speed: 1.0ms preprocess, 62.0ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 1 PAPER, 65.6ms\n",
      "Speed: 0.9ms preprocess, 65.6ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 1 PAPER, 67.4ms\n",
      "Speed: 1.9ms preprocess, 67.4ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 1 PAPER, 66.2ms\n",
      "Speed: 0.9ms preprocess, 66.2ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 1 PAPER, 61.7ms\n",
      "Speed: 1.0ms preprocess, 61.7ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 1 PAPER, 63.3ms\n",
      "Speed: 1.8ms preprocess, 63.3ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 1 PAPER, 65.1ms\n",
      "Speed: 0.9ms preprocess, 65.1ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 1 PAPER, 62.9ms\n",
      "Speed: 1.0ms preprocess, 62.9ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 1 PAPER, 60.4ms\n",
      "Speed: 1.1ms preprocess, 60.4ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 1 PAPER, 62.9ms\n",
      "Speed: 1.0ms preprocess, 62.9ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 1 CARDBOARD, 1 PLASTIC, 65.0ms\n",
      "Speed: 1.0ms preprocess, 65.0ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 1 CARDBOARD, 1 PAPER, 1 PLASTIC, 66.4ms\n",
      "Speed: 1.1ms preprocess, 66.4ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 2 CARDBOARDs, 1 METAL, 1 PAPER, 66.1ms\n",
      "Speed: 0.9ms preprocess, 66.1ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 METAL, 1 PAPER, 63.6ms\n",
      "Speed: 1.0ms preprocess, 63.6ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 METAL, 1 PAPER, 60.4ms\n",
      "Speed: 1.3ms preprocess, 60.4ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 2 CARDBOARDs, 1 METAL, 1 PAPER, 63.8ms\n",
      "Speed: 1.3ms preprocess, 63.8ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 METAL, 1 PAPER, 1 PLASTIC, 66.4ms\n",
      "Speed: 0.9ms preprocess, 66.4ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 METAL, 61.2ms\n",
      "Speed: 2.0ms preprocess, 61.2ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 METAL, 64.5ms\n",
      "Speed: 1.0ms preprocess, 64.5ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 1 CARDBOARD, 1 METAL, 66.4ms\n",
      "Speed: 0.9ms preprocess, 66.4ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 METAL, 1 PAPER, 1 PLASTIC, 62.8ms\n",
      "Speed: 0.9ms preprocess, 62.8ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 1 CARDBOARD, 2 METALs, 1 PAPER, 63.6ms\n",
      "Speed: 0.9ms preprocess, 63.6ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 1 METAL, 66.5ms\n",
      "Speed: 0.9ms preprocess, 66.5ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 66.6ms\n",
      "Speed: 0.9ms preprocess, 66.6ms inference, 0.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 63.1ms\n",
      "Speed: 1.0ms preprocess, 63.1ms inference, 0.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 60.6ms\n",
      "Speed: 1.0ms preprocess, 60.6ms inference, 0.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 PAPER, 63.0ms\n",
      "Speed: 0.9ms preprocess, 63.0ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 PAPER, 61.3ms\n",
      "Speed: 0.9ms preprocess, 61.3ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 PAPER, 2 PLASTICs, 61.1ms\n",
      "Speed: 1.5ms preprocess, 61.1ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 PAPER, 64.9ms\n",
      "Speed: 0.9ms preprocess, 64.9ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 2 PAPERs, 62.5ms\n",
      "Speed: 0.9ms preprocess, 62.5ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 METAL, 3 PAPERs, 60.1ms\n",
      "Speed: 1.6ms preprocess, 60.1ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 3 PAPERs, 60.9ms\n",
      "Speed: 0.9ms preprocess, 60.9ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 3 PAPERs, 4 PLASTICs, 60.3ms\n",
      "Speed: 0.9ms preprocess, 60.3ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 PAPER, 63.2ms\n",
      "Speed: 1.0ms preprocess, 63.2ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 60.8ms\n",
      "Speed: 0.9ms preprocess, 60.8ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 2 PLASTICs, 62.0ms\n",
      "Speed: 1.0ms preprocess, 62.0ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 2 PAPERs, 1 PLASTIC, 66.2ms\n",
      "Speed: 1.0ms preprocess, 66.2ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 2 PAPERs, 63.6ms\n",
      "Speed: 0.8ms preprocess, 63.6ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 PLASTIC, 62.8ms\n",
      "Speed: 1.3ms preprocess, 62.8ms inference, 0.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 PLASTIC, 59.6ms\n",
      "Speed: 1.2ms preprocess, 59.6ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 METAL, 60.3ms\n",
      "Speed: 1.0ms preprocess, 60.3ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 64.4ms\n",
      "Speed: 1.1ms preprocess, 64.4ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 73.2ms\n",
      "Speed: 1.4ms preprocess, 73.2ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 63.3ms\n",
      "Speed: 1.0ms preprocess, 63.3ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 PAPER, 65.7ms\n",
      "Speed: 1.0ms preprocess, 65.7ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 PAPER, 66.1ms\n",
      "Speed: 1.0ms preprocess, 66.1ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 64.9ms\n",
      "Speed: 1.1ms preprocess, 64.9ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 PAPER, 63.5ms\n",
      "Speed: 1.0ms preprocess, 63.5ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 PAPER, 67.2ms\n",
      "Speed: 1.1ms preprocess, 67.2ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 1 PLASTIC, 63.4ms\n",
      "Speed: 1.0ms preprocess, 63.4ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 1 PLASTIC, 68.8ms\n",
      "Speed: 0.9ms preprocess, 68.8ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 69.3ms\n",
      "Speed: 1.2ms preprocess, 69.3ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 64.4ms\n",
      "Speed: 1.3ms preprocess, 64.4ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 61.1ms\n",
      "Speed: 1.2ms preprocess, 61.1ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 61.9ms\n",
      "Speed: 0.9ms preprocess, 61.9ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 60.9ms\n",
      "Speed: 0.9ms preprocess, 60.9ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 PAPER, 64.9ms\n",
      "Speed: 1.2ms preprocess, 64.9ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 PAPER, 62.1ms\n",
      "Speed: 1.0ms preprocess, 62.1ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 65.1ms\n",
      "Speed: 1.4ms preprocess, 65.1ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 64.2ms\n",
      "Speed: 1.1ms preprocess, 64.2ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 61.4ms\n",
      "Speed: 1.0ms preprocess, 61.4ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 61.8ms\n",
      "Speed: 1.1ms preprocess, 61.8ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 64.7ms\n",
      "Speed: 1.1ms preprocess, 64.7ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 2 PLASTICs, 60.1ms\n",
      "Speed: 1.0ms preprocess, 60.1ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 2 PLASTICs, 62.1ms\n",
      "Speed: 1.0ms preprocess, 62.1ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 61.3ms\n",
      "Speed: 1.0ms preprocess, 61.3ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 2 PLASTICs, 65.5ms\n",
      "Speed: 0.9ms preprocess, 65.5ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 2 PLASTICs, 64.1ms\n",
      "Speed: 1.1ms preprocess, 64.1ms inference, 0.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 3 PLASTICs, 61.8ms\n",
      "Speed: 0.9ms preprocess, 61.8ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 3 PLASTICs, 63.5ms\n",
      "Speed: 0.9ms preprocess, 63.5ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 3 PLASTICs, 63.7ms\n",
      "Speed: 1.1ms preprocess, 63.7ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 3 PLASTICs, 67.1ms\n",
      "Speed: 0.8ms preprocess, 67.1ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 3 PLASTICs, 71.5ms\n",
      "Speed: 0.9ms preprocess, 71.5ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 2 PLASTICs, 68.7ms\n",
      "Speed: 1.0ms preprocess, 68.7ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 2 PLASTICs, 74.5ms\n",
      "Speed: 0.9ms preprocess, 74.5ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 2 PLASTICs, 73.3ms\n",
      "Speed: 0.9ms preprocess, 73.3ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 2 PLASTICs, 85.9ms\n",
      "Speed: 1.2ms preprocess, 85.9ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 3 PLASTICs, 78.7ms\n",
      "Speed: 1.1ms preprocess, 78.7ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 3 PLASTICs, 71.8ms\n",
      "Speed: 0.9ms preprocess, 71.8ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 3 PLASTICs, 78.2ms\n",
      "Speed: 1.0ms preprocess, 78.2ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 3 PLASTICs, 80.2ms\n",
      "Speed: 1.1ms preprocess, 80.2ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 3 PLASTICs, 80.3ms\n",
      "Speed: 1.6ms preprocess, 80.3ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 3 PLASTICs, 73.9ms\n",
      "Speed: 1.0ms preprocess, 73.9ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 3 PLASTICs, 77.8ms\n",
      "Speed: 1.1ms preprocess, 77.8ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 3 PLASTICs, 87.7ms\n",
      "Speed: 1.0ms preprocess, 87.7ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 3 PLASTICs, 69.7ms\n",
      "Speed: 0.9ms preprocess, 69.7ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 3 PLASTICs, 72.7ms\n",
      "Speed: 1.0ms preprocess, 72.7ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 3 PLASTICs, 73.7ms\n",
      "Speed: 1.0ms preprocess, 73.7ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 3 PLASTICs, 66.3ms\n",
      "Speed: 1.4ms preprocess, 66.3ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 4 PLASTICs, 65.2ms\n",
      "Speed: 1.0ms preprocess, 65.2ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 4 PLASTICs, 62.9ms\n",
      "Speed: 1.1ms preprocess, 62.9ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 3 PLASTICs, 63.0ms\n",
      "Speed: 1.2ms preprocess, 63.0ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 3 PLASTICs, 65.9ms\n",
      "Speed: 1.0ms preprocess, 65.9ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 3 PLASTICs, 64.9ms\n",
      "Speed: 1.1ms preprocess, 64.9ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 3 PLASTICs, 63.8ms\n",
      "Speed: 1.2ms preprocess, 63.8ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 3 PLASTICs, 63.1ms\n",
      "Speed: 1.0ms preprocess, 63.1ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 3 PLASTICs, 63.4ms\n",
      "Speed: 0.9ms preprocess, 63.4ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 3 PLASTICs, 66.0ms\n",
      "Speed: 0.9ms preprocess, 66.0ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 3 PLASTICs, 66.2ms\n",
      "Speed: 1.1ms preprocess, 66.2ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 3 PLASTICs, 59.6ms\n",
      "Speed: 0.9ms preprocess, 59.6ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 3 PLASTICs, 62.7ms\n",
      "Speed: 0.9ms preprocess, 62.7ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 3 PLASTICs, 60.7ms\n",
      "Speed: 0.9ms preprocess, 60.7ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 3 PLASTICs, 61.2ms\n",
      "Speed: 1.0ms preprocess, 61.2ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 3 PLASTICs, 62.3ms\n",
      "Speed: 1.1ms preprocess, 62.3ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 3 PLASTICs, 61.3ms\n",
      "Speed: 0.9ms preprocess, 61.3ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 3 PLASTICs, 63.6ms\n",
      "Speed: 1.0ms preprocess, 63.6ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 3 PLASTICs, 65.9ms\n",
      "Speed: 0.9ms preprocess, 65.9ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 2 PLASTICs, 69.0ms\n",
      "Speed: 0.8ms preprocess, 69.0ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 2 PLASTICs, 64.9ms\n",
      "Speed: 0.9ms preprocess, 64.9ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 3 PLASTICs, 62.8ms\n",
      "Speed: 1.0ms preprocess, 62.8ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 3 PLASTICs, 63.2ms\n",
      "Speed: 0.9ms preprocess, 63.2ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 3 PLASTICs, 63.2ms\n",
      "Speed: 0.9ms preprocess, 63.2ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 3 PLASTICs, 62.8ms\n",
      "Speed: 1.4ms preprocess, 62.8ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 3 PLASTICs, 62.1ms\n",
      "Speed: 0.9ms preprocess, 62.1ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 2 PLASTICs, 61.2ms\n",
      "Speed: 0.9ms preprocess, 61.2ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 2 PLASTICs, 65.1ms\n",
      "Speed: 2.5ms preprocess, 65.1ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 2 PLASTICs, 66.4ms\n",
      "Speed: 0.9ms preprocess, 66.4ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 3 PLASTICs, 66.9ms\n",
      "Speed: 0.9ms preprocess, 66.9ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 2 PLASTICs, 66.9ms\n",
      "Speed: 1.6ms preprocess, 66.9ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 2 PLASTICs, 67.9ms\n",
      "Speed: 0.9ms preprocess, 67.9ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 3 PLASTICs, 69.2ms\n",
      "Speed: 0.9ms preprocess, 69.2ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 1 PLASTIC, 65.9ms\n",
      "Speed: 0.9ms preprocess, 65.9ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 1 PLASTIC, 66.8ms\n",
      "Speed: 0.9ms preprocess, 66.8ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 1 PLASTIC, 70.9ms\n",
      "Speed: 0.9ms preprocess, 70.9ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 2 BIODEGRADABLEs, 74.8ms\n",
      "Speed: 1.2ms preprocess, 74.8ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 2 BIODEGRADABLEs, 84.5ms\n",
      "Speed: 0.9ms preprocess, 84.5ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 84.6ms\n",
      "Speed: 1.2ms preprocess, 84.6ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 87.7ms\n",
      "Speed: 1.0ms preprocess, 87.7ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 90.6ms\n",
      "Speed: 1.0ms preprocess, 90.6ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 84.9ms\n",
      "Speed: 1.4ms preprocess, 84.9ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 1 PLASTIC, 70.0ms\n",
      "Speed: 1.1ms preprocess, 70.0ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 67.8ms\n",
      "Speed: 1.0ms preprocess, 67.8ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 63.0ms\n",
      "Speed: 0.9ms preprocess, 63.0ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 64.2ms\n",
      "Speed: 1.1ms preprocess, 64.2ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 61.9ms\n",
      "Speed: 0.9ms preprocess, 61.9ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 63.7ms\n",
      "Speed: 1.1ms preprocess, 63.7ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 60.5ms\n",
      "Speed: 1.1ms preprocess, 60.5ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 61.5ms\n",
      "Speed: 0.9ms preprocess, 61.5ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 62.1ms\n",
      "Speed: 1.0ms preprocess, 62.1ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 61.5ms\n",
      "Speed: 1.2ms preprocess, 61.5ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 62.8ms\n",
      "Speed: 0.9ms preprocess, 62.8ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 64.7ms\n",
      "Speed: 0.9ms preprocess, 64.7ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 61.7ms\n",
      "Speed: 0.9ms preprocess, 61.7ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 62.4ms\n",
      "Speed: 0.8ms preprocess, 62.4ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 62.6ms\n",
      "Speed: 1.0ms preprocess, 62.6ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 62.6ms\n",
      "Speed: 1.4ms preprocess, 62.6ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 62.3ms\n",
      "Speed: 0.9ms preprocess, 62.3ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 70.0ms\n",
      "Speed: 1.5ms preprocess, 70.0ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 69.8ms\n",
      "Speed: 1.0ms preprocess, 69.8ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 68.0ms\n",
      "Speed: 1.0ms preprocess, 68.0ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 80.0ms\n",
      "Speed: 1.2ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 1 PLASTIC, 75.1ms\n",
      "Speed: 1.2ms preprocess, 75.1ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 1 PLASTIC, 67.3ms\n",
      "Speed: 0.9ms preprocess, 67.3ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 1 PLASTIC, 62.4ms\n",
      "Speed: 0.9ms preprocess, 62.4ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 62.8ms\n",
      "Speed: 0.9ms preprocess, 62.8ms inference, 0.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 62.9ms\n",
      "Speed: 1.0ms preprocess, 62.9ms inference, 0.4ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 65.7ms\n",
      "Speed: 1.0ms preprocess, 65.7ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 63.8ms\n",
      "Speed: 0.9ms preprocess, 63.8ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 65.4ms\n",
      "Speed: 0.9ms preprocess, 65.4ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 62.4ms\n",
      "Speed: 1.1ms preprocess, 62.4ms inference, 0.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 (no detections), 63.0ms\n",
      "Speed: 1.0ms preprocess, 63.0ms inference, 0.3ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 63.9ms\n",
      "Speed: 1.1ms preprocess, 63.9ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 64.1ms\n",
      "Speed: 1.8ms preprocess, 64.1ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 61.2ms\n",
      "Speed: 0.9ms preprocess, 61.2ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 84.8ms\n",
      "Speed: 1.0ms preprocess, 84.8ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 PAPER, 66.8ms\n",
      "Speed: 1.1ms preprocess, 66.8ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 2 CARDBOARDs, 64.7ms\n",
      "Speed: 1.0ms preprocess, 64.7ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 2 CARDBOARDs, 66.0ms\n",
      "Speed: 1.0ms preprocess, 66.0ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 67.7ms\n",
      "Speed: 1.7ms preprocess, 67.7ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 PAPER, 1 PLASTIC, 63.5ms\n",
      "Speed: 0.9ms preprocess, 63.5ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 PAPER, 1 PLASTIC, 65.5ms\n",
      "Speed: 1.0ms preprocess, 65.5ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 67.8ms\n",
      "Speed: 1.3ms preprocess, 67.8ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 PAPER, 1 PLASTIC, 67.9ms\n",
      "Speed: 0.9ms preprocess, 67.9ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 PAPER, 66.1ms\n",
      "Speed: 1.0ms preprocess, 66.1ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 PAPER, 60.5ms\n",
      "Speed: 1.0ms preprocess, 60.5ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 1 CARDBOARD, 1 PAPER, 66.4ms\n",
      "Speed: 0.9ms preprocess, 66.4ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 2 BIODEGRADABLEs, 1 CARDBOARD, 1 PAPER, 70.2ms\n",
      "Speed: 1.0ms preprocess, 70.2ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 65.0ms\n",
      "Speed: 1.1ms preprocess, 65.0ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 1 CARDBOARD, 2 PAPERs, 62.7ms\n",
      "Speed: 1.2ms preprocess, 62.7ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 BIODEGRADABLE, 1 CARDBOARD, 1 PAPER, 64.0ms\n",
      "Speed: 0.9ms preprocess, 64.0ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 2 PLASTICs, 72.9ms\n",
      "Speed: 1.0ms preprocess, 72.9ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 77.9ms\n",
      "Speed: 1.0ms preprocess, 77.9ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 PAPER, 1 PLASTIC, 76.7ms\n",
      "Speed: 0.9ms preprocess, 76.7ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 75.3ms\n",
      "Speed: 1.0ms preprocess, 75.3ms inference, 0.9ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 2 PLASTICs, 79.1ms\n",
      "Speed: 1.0ms preprocess, 79.1ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 PAPER, 75.9ms\n",
      "Speed: 1.7ms preprocess, 75.9ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 PAPER, 1 PLASTIC, 63.2ms\n",
      "Speed: 1.0ms preprocess, 63.2ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 PAPER, 67.2ms\n",
      "Speed: 0.9ms preprocess, 67.2ms inference, 0.6ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 PAPER, 73.1ms\n",
      "Speed: 1.3ms preprocess, 73.1ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 PAPER, 68.6ms\n",
      "Speed: 0.9ms preprocess, 68.6ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 PAPER, 72.1ms\n",
      "Speed: 1.2ms preprocess, 72.1ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 PAPER, 65.3ms\n",
      "Speed: 1.2ms preprocess, 65.3ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 PAPER, 72.4ms\n",
      "Speed: 1.0ms preprocess, 72.4ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 PAPER, 80.0ms\n",
      "Speed: 0.9ms preprocess, 80.0ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 PAPER, 87.2ms\n",
      "Speed: 1.9ms preprocess, 87.2ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 CARDBOARD, 1 PAPER, 74.9ms\n",
      "Speed: 1.7ms preprocess, 74.9ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 416)\n"
     ]
    }
   ],
   "source": [
    "mode = 'yolo'  # 'yolo' or 'vit'\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"Garbage Classifier\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if mode == 'yolo':\n",
    "        # Run YOLO\n",
    "        results = yolo_model(frame)[0]\n",
    "        boxes = results.boxes\n",
    "\n",
    "        if boxes is not None and len(boxes) > 0:\n",
    "            # Get confidences\n",
    "            confidences = boxes.conf.cpu().numpy()\n",
    "\n",
    "            # Get index of highest confidence\n",
    "            top_idx = confidences.argmax()\n",
    "\n",
    "            # Get just the top box\n",
    "            top_box = boxes[top_idx]\n",
    "\n",
    "            # Plot manually (optional: use results.plot() if fine)\n",
    "            annotated = frame.copy()\n",
    "            x1, y1, x2, y2 = map(int, top_box.xyxy[0])\n",
    "            label = results.names[int(top_box.cls)]\n",
    "            conf = top_box.conf.item()\n",
    "\n",
    "            cv2.rectangle(annotated, (x1, y1), (x2, y2), (255, 0, 255), 2)\n",
    "            cv2.putText(annotated, f\"{label.upper()} {conf:.2f}\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 255), 2)\n",
    "            cv2.putText(annotated, \"YOLO Detection\", (10, annotated.shape[0] - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "    \n",
    "    elif mode == 'vit':\n",
    "        # Run ViT on full frame\n",
    "        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        pil_img = Image.fromarray(img_rgb)\n",
    "        input_tensor = transform(pil_img).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = vit_model(input_tensor)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            label = labels[predicted.item()]\n",
    "\n",
    "        annotated = frame.copy()\n",
    "        cv2.putText(annotated, f\"ViT: {label}\", (10, 40),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "        cv2.putText(annotated, \"ViT Classification\", (10, annotated.shape[0] - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "\n",
    "    # Show result\n",
    "    cv2.imshow(\"Garbage Classifier\", annotated)\n",
    "\n",
    "    # Exit condition\n",
    "    if (cv2.waitKey(1) & 0xFF == ord('q')) or cv2.getWindowProperty(\"Garbage Classifier\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40230045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def predict(image, mode):\n",
    "    frame = np.array(image)\n",
    "    annotated = frame.copy()\n",
    "\n",
    "    if mode == 'yolo':\n",
    "        results = yolo_model(frame)[0]\n",
    "        boxes = results.boxes\n",
    "\n",
    "        if boxes is not None and len(boxes) > 0:\n",
    "            confidences = boxes.conf.cpu().numpy()\n",
    "            top_idx = confidences.argmax()\n",
    "            top_box = boxes[top_idx]\n",
    "\n",
    "            x1, y1, x2, y2 = map(int, top_box.xyxy[0])\n",
    "            label = results.names[int(top_box.cls)]\n",
    "            conf = top_box.conf.item()\n",
    "\n",
    "            cv2.rectangle(annotated, (x1, y1), (x2, y2), (255, 0, 255), 2)\n",
    "            cv2.putText(annotated, f\"{label.upper()} {conf:.2f}\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 255), 2)\n",
    "            cv2.putText(annotated, \"YOLO Detection\", (10, annotated.shape[0] - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    elif mode == 'vit':\n",
    "        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        pil_img = Image.fromarray(img_rgb)\n",
    "        input_tensor = transform(pil_img).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = vit_model(input_tensor)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            label = labels[predicted.item()]\n",
    "\n",
    "        cv2.putText(annotated, f\"ViT: {label}\", (10, 40),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "        cv2.putText(annotated, \"ViT Classification\", (10, annotated.shape[0] - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "\n",
    "    return annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71af8736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\blocks.py:277: UserWarning: api_name predict already exists, using predict_1\n",
      "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n",
      "IMPORTANT: You are using gradio version 3.41.2, however version 4.44.1 is available, please upgrade.\n",
      "--------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\routes.py\", line 488, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\blocks.py\", line 1431, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\blocks.py\", line 1103, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\utils.py\", line 707, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Gauriel\\AppData\\Local\\Temp\\ipykernel_33964\\3943395141.py\", line 29, in predict\n",
      "    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
      "cv2.error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'cvtColor'\n",
      "> Overload resolution failed:\n",
      ">  - src data type = object is not supported\n",
      ">  - Expected Ptr<cv::UMat> for argument 'src'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\routes.py\", line 488, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\blocks.py\", line 1431, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\blocks.py\", line 1103, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\utils.py\", line 707, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Gauriel\\AppData\\Local\\Temp\\ipykernel_33964\\3943395141.py\", line 10, in predict\n",
      "    results = yolo_model(frame)[0]\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\ultralytics\\engine\\model.py\", line 185, in __call__\n",
      "    return self.predict(source, stream, **kwargs)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\ultralytics\\engine\\model.py\", line 555, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\ultralytics\\engine\\predictor.py\", line 227, in __call__\n",
      "    return list(self.stream_inference(source, model, *args, **kwargs))  # merge list of Result into one\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 36, in generator_context\n",
      "    response = gen.send(None)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\ultralytics\\engine\\predictor.py\", line 326, in stream_inference\n",
      "    im = self.preprocess(im0s)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\ultralytics\\engine\\predictor.py\", line 162, in preprocess\n",
      "    im = np.stack(self.pre_transform(im))\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\ultralytics\\engine\\predictor.py\", line 202, in pre_transform\n",
      "    return [letterbox(image=x) for x in im]\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\ultralytics\\engine\\predictor.py\", line 202, in <listcomp>\n",
      "    return [letterbox(image=x) for x in im]\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\ultralytics\\data\\augment.py\", line 1688, in __call__\n",
      "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
      "IndexError: tuple index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 320x416 1 PAPER, 743.3ms\n",
      "Speed: 28.9ms preprocess, 743.3ms inference, 51.0ms postprocess per image at shape (1, 3, 320, 416)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\routes.py\", line 488, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\blocks.py\", line 1434, in process_api\n",
      "    data = self.postprocess_data(fn_index, result[\"prediction\"], state)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\blocks.py\", line 1335, in postprocess_data\n",
      "    prediction_value = block.postprocess(prediction_value)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\components\\image.py\", line 314, in postprocess\n",
      "    return processing_utils.encode_array_to_base64(y)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\processing_utils.py\", line 104, in encode_array_to_base64\n",
      "    pil_image = Image.fromarray(_convert(image_array, np.uint8, force_copy=False))\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\processing_utils.py\", line 476, in _convert\n",
      "    image = _scale(image, 8 * itemsize_in - 1, 8 * itemsize_out)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\processing_utils.py\", line 329, in _scale\n",
      "    if n > m and a.max() < 2**m:\n",
      "TypeError: '<' not supported between instances of 'NoneType' and 'int'\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\routes.py\", line 488, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\blocks.py\", line 1434, in process_api\n",
      "    data = self.postprocess_data(fn_index, result[\"prediction\"], state)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\blocks.py\", line 1335, in postprocess_data\n",
      "    prediction_value = block.postprocess(prediction_value)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\components\\image.py\", line 314, in postprocess\n",
      "    return processing_utils.encode_array_to_base64(y)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\processing_utils.py\", line 104, in encode_array_to_base64\n",
      "    pil_image = Image.fromarray(_convert(image_array, np.uint8, force_copy=False))\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\processing_utils.py\", line 476, in _convert\n",
      "    image = _scale(image, 8 * itemsize_in - 1, 8 * itemsize_out)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\processing_utils.py\", line 329, in _scale\n",
      "    if n > m and a.max() < 2**m:\n",
      "TypeError: '<' not supported between instances of 'NoneType' and 'int'\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\routes.py\", line 488, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\blocks.py\", line 1434, in process_api\n",
      "    data = self.postprocess_data(fn_index, result[\"prediction\"], state)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\blocks.py\", line 1335, in postprocess_data\n",
      "    prediction_value = block.postprocess(prediction_value)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\components\\image.py\", line 314, in postprocess\n",
      "    return processing_utils.encode_array_to_base64(y)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\processing_utils.py\", line 104, in encode_array_to_base64\n",
      "    pil_image = Image.fromarray(_convert(image_array, np.uint8, force_copy=False))\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\processing_utils.py\", line 476, in _convert\n",
      "    image = _scale(image, 8 * itemsize_in - 1, 8 * itemsize_out)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\processing_utils.py\", line 329, in _scale\n",
      "    if n > m and a.max() < 2**m:\n",
      "TypeError: '<' not supported between instances of 'NoneType' and 'int'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\routes.py\", line 488, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\blocks.py\", line 1431, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\blocks.py\", line 1103, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\utils.py\", line 707, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Gauriel\\AppData\\Local\\Temp\\ipykernel_33964\\3943395141.py\", line 10, in predict\n",
      "    results = yolo_model(frame)[0]\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\ultralytics\\engine\\model.py\", line 185, in __call__\n",
      "    return self.predict(source, stream, **kwargs)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\ultralytics\\engine\\model.py\", line 555, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\ultralytics\\engine\\predictor.py\", line 227, in __call__\n",
      "    return list(self.stream_inference(source, model, *args, **kwargs))  # merge list of Result into one\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 36, in generator_context\n",
      "    response = gen.send(None)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\ultralytics\\engine\\predictor.py\", line 326, in stream_inference\n",
      "    im = self.preprocess(im0s)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\ultralytics\\engine\\predictor.py\", line 162, in preprocess\n",
      "    im = np.stack(self.pre_transform(im))\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\ultralytics\\engine\\predictor.py\", line 202, in pre_transform\n",
      "    return [letterbox(image=x) for x in im]\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\ultralytics\\engine\\predictor.py\", line 202, in <listcomp>\n",
      "    return [letterbox(image=x) for x in im]\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\ultralytics\\data\\augment.py\", line 1688, in __call__\n",
      "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
      "IndexError: tuple index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 320x416 1 GLASS, 391.6ms\n",
      "Speed: 8.3ms preprocess, 391.6ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 416)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\routes.py\", line 488, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\blocks.py\", line 1434, in process_api\n",
      "    data = self.postprocess_data(fn_index, result[\"prediction\"], state)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\blocks.py\", line 1335, in postprocess_data\n",
      "    prediction_value = block.postprocess(prediction_value)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\components\\image.py\", line 314, in postprocess\n",
      "    return processing_utils.encode_array_to_base64(y)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\processing_utils.py\", line 104, in encode_array_to_base64\n",
      "    pil_image = Image.fromarray(_convert(image_array, np.uint8, force_copy=False))\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\processing_utils.py\", line 476, in _convert\n",
      "    image = _scale(image, 8 * itemsize_in - 1, 8 * itemsize_out)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\processing_utils.py\", line 329, in _scale\n",
      "    if n > m and a.max() < 2**m:\n",
      "TypeError: '<' not supported between instances of 'NoneType' and 'int'\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\routes.py\", line 488, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\blocks.py\", line 1434, in process_api\n",
      "    data = self.postprocess_data(fn_index, result[\"prediction\"], state)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\blocks.py\", line 1335, in postprocess_data\n",
      "    prediction_value = block.postprocess(prediction_value)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\components\\image.py\", line 314, in postprocess\n",
      "    return processing_utils.encode_array_to_base64(y)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\processing_utils.py\", line 104, in encode_array_to_base64\n",
      "    pil_image = Image.fromarray(_convert(image_array, np.uint8, force_copy=False))\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\processing_utils.py\", line 476, in _convert\n",
      "    image = _scale(image, 8 * itemsize_in - 1, 8 * itemsize_out)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\processing_utils.py\", line 329, in _scale\n",
      "    if n > m and a.max() < 2**m:\n",
      "TypeError: '<' not supported between instances of 'NoneType' and 'int'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 320x416 1 GLASS, 1 METAL, 380.3ms\n",
      "Speed: 9.5ms preprocess, 380.3ms inference, 6.1ms postprocess per image at shape (1, 3, 320, 416)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\routes.py\", line 488, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\blocks.py\", line 1434, in process_api\n",
      "    data = self.postprocess_data(fn_index, result[\"prediction\"], state)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\blocks.py\", line 1335, in postprocess_data\n",
      "    prediction_value = block.postprocess(prediction_value)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\components\\image.py\", line 314, in postprocess\n",
      "    return processing_utils.encode_array_to_base64(y)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\processing_utils.py\", line 104, in encode_array_to_base64\n",
      "    pil_image = Image.fromarray(_convert(image_array, np.uint8, force_copy=False))\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\processing_utils.py\", line 476, in _convert\n",
      "    image = _scale(image, 8 * itemsize_in - 1, 8 * itemsize_out)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\processing_utils.py\", line 329, in _scale\n",
      "    if n > m and a.max() < 2**m:\n",
      "TypeError: '<' not supported between instances of 'NoneType' and 'int'\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\routes.py\", line 488, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\blocks.py\", line 1434, in process_api\n",
      "    data = self.postprocess_data(fn_index, result[\"prediction\"], state)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\blocks.py\", line 1335, in postprocess_data\n",
      "    prediction_value = block.postprocess(prediction_value)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\components\\image.py\", line 314, in postprocess\n",
      "    return processing_utils.encode_array_to_base64(y)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\processing_utils.py\", line 104, in encode_array_to_base64\n",
      "    pil_image = Image.fromarray(_convert(image_array, np.uint8, force_copy=False))\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\processing_utils.py\", line 476, in _convert\n",
      "    image = _scale(image, 8 * itemsize_in - 1, 8 * itemsize_out)\n",
      "  File \"c:\\Users\\Gauriel\\anaconda3\\envs\\DL\\lib\\site-packages\\gradio\\processing_utils.py\", line 329, in _scale\n",
      "    if n > m and a.max() < 2**m:\n",
      "TypeError: '<' not supported between instances of 'NoneType' and 'int'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 320x416 1 METAL, 385.3ms\n",
      "Speed: 13.8ms preprocess, 385.3ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "\n",
      "0: 320x416 1 METAL, 397.2ms\n",
      "Speed: 5.2ms preprocess, 397.2ms inference, 3.9ms postprocess per image at shape (1, 3, 320, 416)\n"
     ]
    }
   ],
   "source": [
    "gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=[\n",
    "        gr.Image(source=\"webcam\", tool=\"editor\", label=\"Input Image\"),  # Webcam input\n",
    "        gr.Radio([\"yolo\", \"vit\"], label=\"Choose Model\", value=\"yolo\")   # Model selector\n",
    "    ],\n",
    "    outputs=gr.Image(label=\"Annotated Output\"),\n",
    "    live=True,\n",
    "    title=\"Garbage Classifier (YOLO + ViT)\"\n",
    ").launch(inbrowser=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
